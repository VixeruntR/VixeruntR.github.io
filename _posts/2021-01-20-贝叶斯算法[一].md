---
layout:     post   				    
title:      朴素贝叶斯算法[一] 				
subtitle:   
date:       2021-01-20 				
author:     WarmStar 						
header-img: img/blog15.jpg 	
catalog: true 				
tags:							
    - ML
---

## 贝叶斯决策论

贝叶斯决策论是以贝叶斯原理为基础，使用概率统计的知识对样本数据集进行分类。贝叶斯方法的特点是结合`先验概率`和`后验概率`，即避免了只使用先验概率的主观偏见，也避免了单独使用样本信息而出现的过拟合现象，在数据集较大的情况下表现出较高的准确率。由于该方法要求所有相关概率都已知，而实际场景中后验概率很难获得，所以应用条件非常苛刻。

为了理解贝叶斯方法，需要先理解`条件概率`的概念和计算方法。

##### 条件概率

设A, B是两个事件，且P(B) > 0。将事件B发生的条件下，事件A发生的概率记为`P(A|B)`。

![hsmyB.jpg](https://s.im5i.com/2021/01/22/hsmyB.jpg)



由文氏图可以看到，事件A和B同时发生的概率为`P(A∩B)`，那么B发生的条件下A发生的概率为

`P(A|B) = P(A∩B)/P(B)`

由上式移项得  `P(A∩B) = P(A|B)P(B)`

同理可以得到  `P(A∩B) = P(B|A)P(A)`

联立两式得到   `P(A|B)P(B)` = `P(B|A)P(A)`

移项可得条件概率公式：![hnUSo.jpg](https://s.im5i.com/2021/01/22/hnUSo.jpg)



##### 全概率公式

上述条件概率公式中的`P(B)`，可以使用全概率公式计算得到，即将一个复杂事件的概率求解问题转化为在不同情况下发生的简单事件的概率求和问题。

![hMfjw.jpg](https://s.im5i.com/2021/01/22/hMfjw.jpg)

如图，假设`S`为样本空间，它是事件`A`与`A'`的和。此时事件`B`可以表示为：

`P(B) = P(B∩A) + P(B∩A')`

由于已知  `P(A∩B) = P(B|A)P(A)`

所以  `P(B) = P(B|A)P(A) + P(B|A')P(A')`。此式就是全概率公式。

将全概率公式代入到条件概率公式可得：

![hMJSF.jpg](https://s.im5i.com/2021/01/22/hMJSF.jpg)



##### 贝叶斯推断

将条件概率公式变形得到：![hnduW.jpg](https://s.im5i.com/2021/01/22/hnduW.jpg)

+ 其中`P(A)`称为`先验概率`，即事件B发生**之前**对事件A的概率的判断。

+ `P(A|B)`称为`后验概率`，即事件B发生**之后**对事件A的概率的重新评估。

+ `P(B|A)/P(B)`称为`可能性函数`，这是一个使得预估概率更接近真实概率的`调整因子`。
  + 如果调整因子的值大于1，意味着先验概率被增强，事件A的发生的可能性变大；
  + 如果调整因子的值等于1，意味着事件B的发生不影响事件A的发生概率；
  + 如果调整因子的值小于1，意味着先验概率被减弱，事件A的发生的可能性变小。

所以贝叶斯推断可描述为`后验概率 = 先验概率 x 调整因子`，即先预估一个先验概率，然后加入实验结果(可能性函数)，看这个实验对先验概率产生了怎样的影响，由此得到更接近实际的后验概率。

##### 



##### 实例

其实条件概率举个最直白的例子就是：现在知道一个生物是个人(已知条件)，那这个生物是男人的概率是50%；现在知道另一个生物是个男人(已知条件)，那这个生物是人的概率是100%。











## 朴素贝叶斯

朴素贝叶斯法是基于**贝叶斯决策论**与**特征条件独立性假设**的分类方法。所谓特征条件独立性假设，即对于已知的类别，所有特征相互独立，换句话说就是每一种特征独立地对分类结果产生影响。这一特点其实也就是`朴素`的含义。

反映到实际计算里就是：给定数据集后，对于一组没有分好类别的新数据，根据新数据的特征值，计算出该组数据属于数据集中每个类别的概率，得到的概率值最大的类即认为该组数据属于该类别。