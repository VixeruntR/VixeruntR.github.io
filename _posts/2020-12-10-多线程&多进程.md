---
layout:     post   				    
title:      Python多线程与多进程 				
subtitle:   
date:       2020-12-10 				
author:     WarmStar 						
header-img: img/blog6.jpg 	
catalog: true 				
tags:							
    - Python
---



## 简介

##### 线程

线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。  

<br/>

##### 进程

进程是指一个程序在给定数据集合上的一次执行过程，是系统进行资源分配和调度的基本单位。可以简单地理解为操作系统中正在执行的一个程序，也就是说每个程序都有一个自己的独立的进程。每一个进程启动时都会先产生一个主线程，然后主线程再创建子线程。进程是线程的容器，程序是指令、数据及其组织形式的描述，进程是程序的实体。  

##### 线程和进程的区别

这里将进程比作火车，线程比作车厢。

- 线程必须在进程中执行（单纯的车厢无法运行）

- 一个进程可以包含多个线程，有且只有一个主线程（一辆火车可以有多个车厢）

- 不同进程间的数据很难共享（不同火车上的乘客很难互换，需要站点换乘）

- 同一进程下不同线程间数据容易共享（乘客在车厢间走动很容易）

- 进程要比线程消耗更多的计算机资源（总车箱数相同时，列车数越少耗费资源越少）

- 进程间不会相互影响，一个线程挂掉将可能导致整个进程挂掉（一列火车上的某节车厢着火了，将影响到整个列车）

- 进程可以拓展到多机，线程最多适合多核（不同火车可以行驶在不同轨道上，同一火车的车厢不能行驶在不同的轨道上）

- 进程使用的内存地址可以上锁。一个线程使用某些共享内存时，其他线程必须等待它试用结束，才能使用这一块内存。（比如火车上的洗手间）－**互斥锁**

- 进程使用的内存地址可以x限制使用量（比如火车上的餐厅，最多只允许固定数量的乘客进入，如果客满了其余乘客需要等待）－**信号量**  

    

## Python 多线程

### 创建多线程

Python提供的内置的`threading`模块可用于线程的创建和管理。

##### 方法1

直接使用`threading.Thread()`创建：其中`target`参数传递的变量为线程需要执行的函数名(不带括号)，`args`参数传递函数所需的变量(以元组传递)。

```python
import threading

def run(i):
    print("current task:", i)

if __name__ == '__main__':
    t1 = threading.Thread(target=run, args=(1,))
    t2 = threading.Thread(target=run, args=(2,))
    t1.start()
    t2.start()
```

##### 方法2

继承`threading.Thread`自定义线程类，必须重写`run()`方法：因为原始的`threading.Thread`实例在执行`start()`方法后会自动调用`run()`方法，所以这里在继承`threading.Thread`类后，必须将执行函数命名为`run()`。

```python
import threading

class MyThread(threading.Thread):
    def __init__(self, i):
        super(MyThread, self).__init__()
        self.i = i

    def run(self):
        print("current task:", self.i)

if __name__ == "__main__":
    t1 = MyThread(1)
    t2 = MyThread(2)
    t1.start()
    t2.start()
```

### 守护线程

##### setDeamon([bool])方法

设置子线程为`后台线程(True)`或`前台线程(False)`，默认为`前台线程(False)`。如果置为前台线程，那么当主线程执行完毕时，会等待前台线程执行完成后，程序才停止，但主线程可以提前停止；如果置为后台线程，那么当主线程执行完毕时，无论后台线程是否执行完成，主线程和后台线程均停止。

**① 设置`setDaemon(False)`**

```python
import threading
import time

def run(i):
    print("current task:", i)
    time.sleep(1)
    print("current thread name:", threading.currentThread().getName())
    time.sleep(1)

if __name__ == "__main__":
    test_start = time.time()
    for i in range(2):
        t = threading.Thread(target=run, args=(i + 1,))
        t.setDaemon(False)
        t.start()
    test_end = time.time()
    print('Main thread takes time: ', round(test_end - test_start, 2))
    print('The main thread is finished !')
```

**输出结果：**主线程先执行完毕，等到子线程也都执行完毕，程序才结束。

```python
current task: 1
current task: 2
Main thread takes time:  0.0
The main thread is finished !
current thread name: Thread-1
current thread name: Thread-2
```

**② 设置`setDaemon(True)`**

```python
import threading
import time

def run(i):
    print("current task:", i)
    time.sleep(1)
    print("current thread name:", threading.currentThread().getName())
    time.sleep(1)

if __name__ == "__main__":
    test_start = time.time()
    for i in range(2):
        t = threading.Thread(target=run, args=(i + 1,))
        t.setDaemon(True)
        t.start()
    test_end = time.time()
    print('Main thread takes time: ', round(test_end - test_start, 2))
    print('The main thread is finished !')
```

**输出结果：**主线程执行完后程序直接结束，不会等待子线程执行完毕。

```python
current task: 1
current task: 2
Main thread takes time:  0.0
The main thread is finished !
```

##### join([timeout])方法

`join()`会在主线程执行结束后，使主程序进入阻塞状态，直到调用此方法的子线程执行结束或主线程等待到达指定的`timeout`时间，否则设置了`setDeamon(True)`主线程也要等待。

**① 不指定timeout时间，设置setDaemon(False)**

```python
def run(i, delay):
    print("current task:", i)
    time.sleep(delay)
    print("current thread name:", threading.currentThread().getName())
    time.sleep(delay)

if __name__ == "__main__":
    test_start = time.time()
    thread_list = []
    for i in range(2):
        t = threading.Thread(target=run, args=(i + 1, (i + 1) * 5))
        thread_list.append(t)
    for t in thread_list:
        t.start()
    for t in thread_list:
        t.join()
    test_end = time.time()
    print('Main thread takes time: ', round(test_end - test_start, 2))
    print('The main thread is finished !')
```

**输出结果：**主线程会等待所有子线程执行完毕后才结束。

```python
current task: 1
current task: 2
current thread name: Thread-1
current thread name: Thread-2
Main thread takes time:  20.0
The main thread is finished !
```

**② 指定timeout时间，设置setDaemon(False)**

```python
def run(i, delay):
    print("current task:", i)
    time.sleep(delay)
    print("current thread name:", threading.currentThread().getName())
    time.sleep(delay)

if __name__ == "__main__":
    test_start = time.time()
    thread_list = []
    for i in range(2):
        t = threading.Thread(target=run, args=(i + 1, (i + 1) * 5))
        thread_list.append(t)
    for t in thread_list:
        t.start()
    for t in thread_list:
        t.join(timeout=2)
    test_end = time.time()
    print('Main thread takes time: ', round(test_end - test_start, 2))
    print('The main thread is finished !')
```

**输出结果：**主线程等待每个子线程的`timeout`时间总和之后结束，但不会杀死子线程，子线程依旧继续执行直到正常结束。相比于上一种情况来说，就是主线程会等，但不是无限期的等。

```python
current task: 1
current task: 2
Main thread takes time:  4.0
The main thread is finished !
current thread name: Thread-1
current thread name: Thread-2
```

**③ 不指定timeout时间，设置setDaemon(True)**

```python
def run(i, delay):
    print("current task:", i)
    time.sleep(delay)
    print("current thread name:", threading.currentThread().getName())
    time.sleep(delay)

if __name__ == "__main__":
    test_start = time.time()
    thread_list = []
    for i in range(2):
        t = threading.Thread(target=run, args=(i + 1, (i + 1) * 5))
        t.setDaemon(True)
        thread_list.append(t)
    for t in thread_list:
        t.start()
    for t in thread_list:
        t.join()
    test_end = time.time()
    print('Main thread takes time: ', round(test_end - test_start, 2))
    print('The main thread is finished !')
```

**输出结果：**虽然设置了`setDaemon(True)`，由于使用了`join()`方法，主线程依旧等待子线程执行完才结束，共耗时`20s`，就是所有子线程里耗时最长的那一个所用的时间。

```python
current task: 1
current task: 2
current thread name: Thread-1
current thread name: Thread-2
Main thread takes time:  20.0
The main thread is finished !
```

**④ 指定timeout时间，设置setDaemon(True)**

```python
def run(i, delay):
    print("current task:", i)
    time.sleep(delay)
    print("current thread name:", threading.currentThread().getName())
    time.sleep(delay)

if __name__ == "__main__":
    test_start = time.time()
    thread_list = []
    for i in range(2):
        t = threading.Thread(target=run, args=(i + 1, (i + 1) * 5))
        t.setDaemon(True)
        thread_list.append(t)
    for t in thread_list:
        t.start()
    for t in thread_list:
        t.join(timeout=2)
    test_end = time.time()
    print('Main thread takes time: ', round(test_end - test_start, 2))
    print('The main thread is finished !')
```

**输出结果：**主线程共耗时`4s`，即主线程等待所有子线程的`timeout`时间总和之后，子线程就被杀死了，程序结束。

```python
current task: 1
current task: 2
Main thread takes time:  4.0
The main thread is finished !
```



### 线程锁

当多个线程共享同样的资源时，就会存在资源争夺和锁的问题，如果不能很好地进行`线程同步`，多个线程同时操作一段内存中的资源容易发生混乱。下面介绍一下为何会出现错误以及如何避免错误。

##### 全局解释锁(GIL)

`GIL`即`Global Interpreter Lock`，全局解释锁。GIL被设计用以保护线程安全，它保证同一时刻只有一个线程在一个CPU上执行**字节码**，即使是在多CPU的处理器上，使用GIL的解释器也无法将多个线程映射到多个CPU上，这是`CPython`解释器的缺陷。

实际上即使有了GIL，这个问题也无法完全解决，因为GIL也会释放，而且它并不是在某个线程执行完成后才释放，而是根据代码的字节码或者时间片`[调用了time.sleep()]`进行释放。看一个小例子，这里设置一个全局变量`result`作为共享资源：

```python
result = 0

def add():
    global result
    for i in range(1000000):
        result += 1

def desc():
    global result
    for i in range(1000000):
        result -= 1

if __name__ == '__main__':
    t1 = threading.Thread(target=add)
    t2 = threading.Thread(target=desc)
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    print(result)
```

这段程序正常来说，就是将`result`都执行加减操作各一百万次，最后的结果应该是0。但其实运行这段程序多次，都会得到不同的结果，有正有负。这就牵涉到了GIL释放的问题，看一个实现简单加法程序的`字节码`帮助理解：

```python
import dis

def sample_add(a):
    a += 1
    return a

print(dis.dis(sample_add))
```

输出结果：

```python
  5           0 LOAD_FAST                0 (a)
              2 LOAD_CONST               1 (1)
              4 INPLACE_ADD
              6 STORE_FAST               0 (a)

  6           8 LOAD_FAST                0 (a)
             10 RETURN_VALUE
```

可以看到`a += 1`这一句简单的加法操作的执行过程，是先将变量`a`装载入CPU，再将常量`1`装载入CPU，然后执行加法操作，最后将`a`存储在内存中，**并不是简单一步加操作就执行完毕的**。而GIL不是根据Python代码段释放，它是**根据字节码或者时间片释放**的，再回到第一个例子里，如果第一个线程执行`add`函数时，在执行完某次加法操作后还未将`result`保存在内存中时，GIL就释放了，接着`desc`函数就会获得执行权，此时该函数装载的变量`result`还是未进行加法操作时的值，也就相当于本次加法操作失去作用，在多次循环后，程序的最终运行结果自然不是0了。这种情况称为`竞态条件(race condition)`，可以使用锁解决。



##### 同步锁

Python提供的`threading.Lock()`和`threading.Rlock()`类可以实现锁。二者的主要区别在于`threading.Rlock()`是**可重入锁**，即同一个线程可以进行多次锁定和释放，但必须保证`acquire()` 和`release()`成对出现；而`threading.Lock()`每次只能锁定一次，不能嵌套加锁。

+ `acquire([timeout])`: 获得锁定，使线程进入同步阻塞状态。
+ ` release()`: 释放锁。释放的线程必须已获得锁定，否则抛出异常

```python
result = 0
lock = threading.RLock()

def add():
    global result
    global lock
    for i in range(1000000):
        lock.acquire()
        result += 1
        lock.release()

def desc():
    global result
    global lock
    for i in range(1000000):
        lock.acquire()
        result -= 1
        lock.release()

if __name__ == '__main__':
    t1 = threading.Thread(target=add)
    t2 = threading.Thread(target=desc)
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    print(result)

```

在这段程序里，`threading.Rlock()`实例化一个锁对象`lock`，当一个线程获得锁时，另一个线程在`acquire`处阻塞，直到当前获得锁的线程执行 `release`释放锁之后才可以和其它线程共同争夺锁。`acquire`和`release`之间的代码段执行时不会切换到其他线程，保证了操作的完整性。但这样做虽然保证了资源的安全调用，也带来了额外的操作时间开销，上述例子中，使用同步锁比不使用消耗的时间足足多了7倍。  



##### 死锁

死锁是指多个线程互相持有其它线程当前需要的资源，且都不释放当前占有的资源，导致这些线程处于等待状态，导致程序无法继续执行的情况。

```python
class ClassA(object):
    def __init__(self):
        self.lock = threading.RLock()

    def startA(self, b):
        self.lock.acquire()
        time.sleep(5)
        b.info()
        self.lock.release()

    def info(self):
        self.lock.acquire()
        print("ClassA info")
        self.lock.release()

class ClassB(object):
    def __init__(self):
        self.lock = threading.RLock()

    def startB(self, a):
        self.lock.acquire()
        time.sleep(5)
        a.info()
        self.lock.release()

    def info(self):
        self.lock.acquire()
        print("ClassB info")
        self.lock.release()

def runA():
    ca.startA(cb)

def runB():
    cb.startB(ca)

if __name__ == '__main__':
    ca = ClassA()
    cb = ClassB()
    t1 = threading.Thread(target=runA)
    t2 = threading.Thread(target=runB)
    t1.start()
    t2.start()
    t1.join()
    t2.join()
```

这段程序中，`ClassA`获得锁后执行`sleep(5)`，此时 A 的锁还未释放就去申请 B 的锁，而 B 也在做同样的事，仍然是未释放自己的锁就去申请 A 的锁，于是造成死锁。



## Python多进程

### 创建多进程

Python提供的内置的`muiltprocessing`模块可用于进程的创建和管理。

##### 方法1

直接使用`multiprocessing.Process`创建：

```python
import multiprocessing

def run(i):
    print("current task:", i)

if __name__ == '__main__':
    p1 = multiprocessing.Process(target=run, args=(1,))
    p2 = multiprocessing.Process(target=run, args=(2,))
    p1.start()
    p2.start()
```

##### 方法2

继承`multiprocessing.Process`自定义进程类，必须重写`run()`方法：

```python
import multiprocessing

class MyProcess(multiprocessing.Process):
    def __init__(self, i):
        super(MyProcess, self).__init__()
        self.i = i

    def run(self):
        print("current task:", self.i)

if __name__ == "__main__":
    p1 = MyProcess(1)
    p2 = MyProcess(2)
    p1.start()
    p2.start()
```



### 进程池

创建多个进程时，可以直接使用`Pool([processes])`模块。常用方法如下表：

|     方法      |                             作用                             |
| :-----------: | :----------------------------------------------------------: |
|    apply()    |                       同步执行（串行）                       |
| apply_async() |                       异步执行（并行）                       |
|  terminate()  |                        立刻关闭进程池                        |
|    join()     | 主进程等待所有子进程执行完毕，必须在close()或terminate()之后使用 |
|    close()    |               等待所有进程结束后，才关闭进程池               |

下面是一个小的示例程序。其中`cpu_count()`表示当前设备CPU核心数，进程池创建的进程数可以为任意整数，但同一时刻并行执行的进程不会超过CPU核心数。

```python
from multiprocessing import Pool
from multiprocessing import cpu_count

def run(flag):
    print("Current Pool:", flag)

if __name__ == "__main__":
    pool = Pool(processes=cpu_count())
    for i in range(cpu_count() * 2):
        pool.apply_async(run, args=(i,))
    pool.close()
    pool.join()
```



### 进程间通信

进程之间是不共享数据的，如果进程之间需要通信，可以用`Queue`模块或者`Pipi`模块。

##### Queue([maxsize])

`Queue`是多进程安全的队列，可以实现多进程之间的数据传递，主要用到两个函数:

+ `put([block=True, timeout=None])`: 用以将数据插入队列中，有两个可选参数`blocked`和`timeout`。如果`blocked=True`，写入是阻塞式的，程序会在队列写满后阻塞`timeout`指定的时间，等待队列中有数据被其它进程取走，如果等待超时则会抛出`Queue.Full`异常。如果`blocked=False`，写入是非阻塞式的，当队列写满时会直接抛出`Queue.Full`异常。
+ `get([block=True, timeout=None])`: 用以从队列中读取并删除一个元素数据，有两个可选参数`blocked`和`timeout`。如果`blocked=True`，取出是阻塞式的，程序会在队列为空后阻塞`timeout`指定的时间，等待队列中有数据被其它进程写入，如果等待超时就会抛出`Queue.Empty`异常。如果`blocked=False`，取出时非阻塞式的，当队列里有值可取时，会直接返回该值，否则如果队列为空，则立即抛出`Queue.Empty`异常。

```python
from multiprocessing import Process, Queue

def put(que):
    que.put('Sample demo')
    print(que.get())

if __name__ == '__main__':
    queue = Queue(10)
    p = Process(target=put, args=(queue,))
    p.start()
    print(queue.get())
    queue.put('Write message')
    p.join()
    
------------------------------------------------------------------------
>> Sample demo
>> Write message
```



##### Pipe([duplex])

`Pipe`用于两个进程间通信，两个进程分别位于管道的两端，本质时用管道传递数据而不是数据共享。`Pipe()` 创建后返回两个对象，分别表示管道的两端，每端都有`send()` 和`recv()`两个函数。

+ 简单示例

```python
from multiprocessing import Process, Pipe

def send(pipe):
    pipe.send(['pipe'] + ['test', 'demo'])
    pipe.close()

if __name__ == '__main__':
    con1, con2 = Pipe()
    p = Process(target=send, args=(con1,))
    p.start()
    print("con2 receive: %s" % con2.recv())
    con2.close()
    
------------------------------------------------------------------------
>> con2 receive: ['pipe', 'test', 'demo']
```

+ 管道同时发送和接收数据

```python
from multiprocessing import Process, Pipe

def talk(pipe):
    pipe.send(dict(name='Test', age=42))
    received = pipe.recv()
    print('con2 receive:', received)

if __name__ == '__main__':
    con1, con2 = Pipe()
    p = Process(target=talk, args=(con2,))
    p.start()
    print('con1 receive:', con1.recv())
    con1.send([x for x in 'demo'])
    p.join()
    
------------------------------------------------------------------------
>> con1 receive: {'name': 'Test', 'age': 42}
>> con2 receive: ['d', 'e', 'm', 'o']
```



## 如何选择？

程序一般分为`CPU密集型`和`I/O密集型`。如果程序属于`CPU密集型`，选择`多进程`更适宜；如果程序属于`I/O密集型`，选择`多线程`更适宜。

+ CPU 密集型：也称为计算密集型，程序比较偏重于计算。I/O操作在很短的时间就可以完成，而CPU还有许多运算要处理，CPU Loading很高。例如科学计算的程序，机器学习的程序，视频高清解码的程序等。
+ I/O 密集型：程序计算量较少，但需要执行大量I/O操作，CPU Loading很低。爬虫程序就是典型的 I/O 密集型程序。

