---
layout:     post   				    
title:      决策树算法[二] 				
subtitle:    
date:       2021-01-15 				
author:     WarmStar 						
header-img: img/blog14.jpg 	
catalog: true 				
tags:							
    - ML						
---

> python=3.6
>
> scikit-learn=0.23.1

### sklearn实现决策树

`sklearn.tree`模块提供了决策树的相关算法实现，可以用于分类和回归问题，也提供了对应的可视化函数。

##### 函数介绍

`sklearn.tree`模块提供的`DecisionTreeClassifier`函数可以实现用决策树解决分类问题，该函数的参数如下：

- **criterion：**特征选择的方法，默认是`gini`，也可以设置为`entropy`。`entropy`是香农熵；`gini`是基尼不纯度，表示一个随机样本在子集中被分错的可能性，即该样本被选中的概率乘以它被分错的概率，当一个节点中所有样本都是一个类时，基尼不纯度为零。

- **splitter：**特征划分点的选择标准，默认是`best`，也可以设置为`random`。`best`参数是根据算法的结果选择最佳的切分特征，适合样本量不大的情况；`random`是随机在部分划分点中找**局部最优**的划分点，适合样本量非常大的情况。

- **max_depth：**决策树的最大深度，默认是`None`，此时决策树在建立树的时候不会限制深度，会一直加深直到自然结束。如果样本量很大且特征也多的情况下，根绝实际数据的分布限制最大深度，可能可以得到更好的分类效果。

- **min_samples_split：**内部节点再划分所需最小样本数，默认是2，这个值是限制子树继续划分的条件。如果该参数为整数，那么在切分内部节点的时候，当样本数量小于该值时就会停止切分；如果该参数为浮点数，那么以该值计算出的`math.ceil(min_samples_split * n_samples)`作为可继续切分的最小样本量。

- **min_samples_leaf：**叶子节点上的最小样本数，默认是1。这个值是控制得到的叶子节点是否保留的最小值，当叶子节点上的样本数目小于该值则会被剪枝。如果该值是浮点数，则计算出`math.celi(min_samples_leaf * n_samples)`作为该参数的值。

- **min_weight_fraction_leaf：**叶子节点最小的样本权重和，默认是0。这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值则会被剪枝。

- **max_features：**

  划分时考虑的最大特征数，默认是None。定义`n_features`为总特征数：

  - 如果max_features是整数，则考虑`max_features`个特征
  - 如果max_features是浮点数，则考虑`int(max_features * n_features)`个特征
  - 如果max_features设为`auto`，那么`max_features = sqrt(n_features)`
  - 如果max_features设为`sqrt`，那么`max_featrues = sqrt(n_features)`
  - 如果max_features设为`log2`，那么`max_features = log2(n_features)`
  - 如果max_features设为`None`，那么`max_features = n_features`

- **random_state：**随机数种子，默认是`None`。

- **max_leaf_nodes：**最大叶子节点数，默认是`None`。限制最大叶子节点数，可以防止过拟合。如果加了限制，算法会在最大叶子节点数的限制内建立最优的决策树。

- **class_weight：**类别权重，默认是`None`。可以传入字典、字典列表或者`balanced`。传入的参数是为了指定样本集中各类别的的权重，防止训练集中某些类别的样本过多，导致训练的决策树的结果偏向这些类别。如果使用`balanced`，算法则自动计算权重，样本量少的类对应的权重会高。



##### 注意事项

+ 当样本数量较少但特征数量很多的时候，决策树容易过拟合。此时可以先进行维度规约，例如使用`主成分分析(PCA)`、`特征选择(Losso)`或者`独立成分分析(ICA)`等方法，可以减少特征维度。
+ 在训练分类模型时，需预先观察样本的类别分布情况，如果分布不均匀，需要考虑用`class_weight`参数调整权重。
+ 如果输入的样本矩阵是稀疏的，可以在拟合前和预测前都调用`csc_matrix`稀疏化。

<br/>

### 数据集

[数据集来源UCI数据库，下载地址](https://github.com/VixeruntR/MyData/blob/master/DecisionTree/lenses.txt)

下面的数据是根据人的几项特征分类其需要什么类型的隐形眼镜的简单数据集，其中第一列表示年龄范围，第二列表示症状，第三列表示是否散光，第四列表示流泪程度，第五列是标签(分为硬材质(hard)、软材质(soft)和不适合佩戴隐形眼镜(no lenses))：

![TTeEz.jpg](https://s.im5i.com/2021/01/18/TTeEz.jpg)

##### 数据加载

```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder

def load_dataset():
    with open('lenses.txt', 'r') as f:
        all_data = [data.strip().split('\t') for data in f.readlines()]

    labels = []
    for data in all_data:
        labels.append(data[-1])

    dataset = {}
    label_names = ['age', 'prescript', 'astigmatic', 'tearRate']
    temp = []
    for label_name in label_names:
        for data in all_data:
            temp.append(data[label_names.index(label_name)])
        dataset[label_name] = temp
        temp = []
    dataset_pd = pd.DataFrame(dataset)
    return dataset_pd, labels
```

示例代码是读取`lenses.txt`文件，然后将其转化为`pandas.DataFrame`格式，如下图：

![T8mxf.jpg](https://s.im5i.com/2021/01/18/T8mxf.jpg)

当然`string`类型的数据是无法训练的，需要将其序列化转换为模型可读的形式，这里使用`LabelEncoder`将字符串编码为增量整数值：

```python
from sklearn.preprocessing import LabelEncoder

def dataset_process(dataset):
    le = LabelEncoder()
    for c in dataset.columns:
        dataset[c] = le.fit_transform(dataset[c])
    return dataset

if __name__ == '__main__':
    dataset_pd, labels = load_dataset()
    dataset = dataset_process(dataset_pd)
    print(dataset)
```

转换后的数据形式如下图所示，此时得到的数据就可以用以决策树训练了：

![TFSth.jpg](https://s.im5i.com/2021/01/18/TFSth.jpg)

<br/>

### 训练&可视化

##### 训练&预测

使用`sklearn`封装好的函数进行训练和预测的代码都非常简单，但需注意**预测时的数据维度**：

```python
if __name__ == '__main__':
    dataset_pd, labels = load_dataset()
    dataset = dataset_process(dataset_pd)

    dtc = DecisionTreeClassifier(criterion='entropy', max_depth=4)
    dtc = dtc.fit(dataset.values.tolist(), labels)
    test_data = [[2, 1, 1, 0]]
    result = dtc.predict(test_data)
    print(result)
```

##### 保存&加载

除了之前介绍的 [pickle模块](https://vixeruntr.github.io/2021/01/12/ML%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91-%E4%B8%80/#%E5%AD%98%E5%82%A8%E5%92%8C%E5%8A%A0%E8%BD%BD) 可以保存和加载模型之外，还可以使用`joblib`模块保存和加载模型，并且`joblib`模块速度更快，代码也更简单：

```python
import joblib

if __name__ == '__main__':
    dataset_pd, labels = load_dataset()
    dataset = dataset_process(dataset_pd)

    dtc = DecisionTreeClassifier(criterion='entropy', max_depth=4)
    dtc = dtc.fit(dataset.values.tolist(), labels)
    joblib.dump(dtc, 'dtc.pkl')
    model = joblib.load('dtc.pkl')
    test_data = [2, 1, 1, 0]
    result = model.predict([test_data])
    print(result)
```

##### 可视化

为了直观地展示和查看训练得到的决策树，使其可视化结果符合人的习惯，可以使用下述方法：

1. 安装`pydotplus`，直接使用`pip`安装即可

```python
pip install pydotplus
```

2. 安装`Graphviz`

   [官网下载](https://www.graphviz.org/) 或者去其它三方网站下载安装。

   如果是`windows`系统需要在安装完成后将`bin`目录添加到环境变量中，例如直接安装在 F盘根目录，那么就需要把`F:\Graphviz\bin`添加到环境变量中去。

3. 代码如下，如果添加了环境变量仍然报错`GraphViz's executables not found`，可以添加`os.environ["PATH"] += os.pathsep + r'F:\Graphviz\bin'`这行代码。

   ```python
   import pydotplus
   from sklearn import tree
   from six import StringIO
   import os
   
   os.environ["PATH"] += os.pathsep + r'F:\Graphviz\bin'
   
   if __name__ == '__main__':
       dataset_pd, labels = load_dataset()
       dataset = dataset_process(dataset_pd)
       dtc = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)
       dtc = dtc.fit(dataset.values.tolist(), labels)
       dot_data = StringIO()
       tree.export_graphviz(dtc,
                            out_file=dot_data,
                            feature_names=dataset.keys(),
                            class_names=dtc.classes_,
                            filled=True,
                            rounded=True,
                            special_characters=True)
       graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
       graph.write_pdf("tree.pdf")
   ```

   运行后在当前目录下得到一个`tree.pdf`文件，打开后可以看到如下内容：

   ![TmDfy.jpg](https://s.im5i.com/2021/01/19/TmDfy.jpg)

   

   

   